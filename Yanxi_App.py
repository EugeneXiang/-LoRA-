from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import gradio as gr
import re
from collections import Counter

# 1. åŠ è½½é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ä¸ tokenizer
base_model_name = "gpt2-medium"
tokenizer = AutoTokenizer.from_pretrained(base_model_name)
tokenizer.add_special_tokens({'pad_token': '[PAD]'})

model = AutoModelForCausalLM.from_pretrained(base_model_name, ignore_mismatched_sizes=True)
model.resize_token_embeddings(len(tokenizer))

# 2. åŠ è½½ adapter æƒé‡ï¼ˆè¿™é‡Œ adapter æ–‡ä»¶å¤¹éœ€è¦æ˜¯ç”¨ PEFT ä¿å­˜çš„å®Œæ•´ adapter æ–‡ä»¶å¤¹ï¼‰
adapter_path = "/Users/eugenexiang/AI_Yanxi/yanxi_lora_output_v2"
model = PeftModel.from_pretrained(model, adapter_path, ignore_mismatched_sizes=True)

def remove_input_repetition(response, input_text):
    # æå–æ‰€æœ‰é•¿åº¦åœ¨5~30ä¹‹é—´çš„å­ä¸²
    substrings = [input_text[i:i+15] for i in range(len(input_text) - 14)]
    freq = Counter(substrings)
    # æ‰¾å‡ºå‡ºç°é¢‘ç‡å¤§äº2æ¬¡çš„â€œå¤è¯»â€ç‰‡æ®µ
    repeated_phrases = [phrase for phrase, count in freq.items() if count > 2]

    # å»é™¤æ‰€æœ‰å¤è¯»ç‰‡æ®µ
    for phrase in repeated_phrases:
        response = response.replace(phrase, "")

    # å»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹é‡å¤
    response = re.sub(r"\s{2,}", " ", response)
    response = re.sub(r"(ã€‚){2,}", "ã€‚", response)

    return response.strip()

def generate_reply(user_input):
    # è‡ªåŠ¨æ·»åŠ æç¤ºï¼Œé˜²æ­¢é‡å¤é—®é¢˜
    if "ã€é—®é¢˜ã€‘" in user_input and "ã€ç»“è®ºã€‘" in user_input:
        user_input += "\nè¯·ç›´æ¥å›ç­”ï¼Œä¸è¦é‡å¤é—®é¢˜å†…å®¹ã€‚"

    input_ids = tokenizer.encode(user_input, return_tensors="pt", truncation=True)
    output_ids = model.generate(
        input_ids,
        max_length=200,
        do_sample=False,
        top_p=0.9,
        top_k=50,
        temperature=0.8,
        num_beams=4,
        early_stopping=True,
        repetition_penalty=1.5
    )
    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    response = remove_input_repetition(response, user_input)
    return response

with gr.Blocks(theme=gr.themes.Soft()) as iface:
    gr.Markdown("# ğŸŒ¸ è¨€çŠ€ Â· æ™ºæ…§å›å“")
    gr.Markdown("æ¬¢è¿æ¥åˆ°è¨€çŠ€äº¤äº’ç•Œé¢ï¼Œè¾“å…¥ä½ çš„é—®é¢˜ï¼Œçœ‹çœ‹è¿™ä¸ªAIå­©å­æ€ä¹ˆå›ä½ å˜´ğŸ‘¶ğŸ§ ")

    with gr.Row():
        user_input = gr.Textbox(label="ğŸ—£ï¸ ä½ è¯´ï¼š", lines=3, placeholder="è¾“å…¥ä½ çš„æ¶ˆæ¯...")

    with gr.Row():
        output = gr.Textbox(label="ğŸ¤– è¨€çŠ€çš„å›åº”", lines=8, interactive=False)

    send_btn = gr.Button("âœ¨ å‘å‡ºä½ çš„Promptï¼")

    def generate_and_clean(text):
        return generate_reply(text)

    send_btn.click(generate_and_clean, inputs=user_input, outputs=output)
    user_input.submit(generate_and_clean, inputs=user_input, outputs=output)

if __name__ == "__main__":
    iface.launch()